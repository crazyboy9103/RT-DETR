Initialized distributed mode...
cfg:  {'task': 'detection', '_model': None, '_postprocessor': None, '_criterion': None, '_optimizer': None, '_lr_scheduler': None, '_lr_warmup_scheduler': None, '_train_dataloader': None, '_val_dataloader': None, '_ema': None, '_scaler': None, '_train_dataset': None, '_val_dataset': None, '_collate_fn': None, '_evaluator': None, '_writer': None, 'num_workers': 0, 'batch_size': None, '_train_batch_size': None, '_val_batch_size': None, '_train_shuffle': None, '_val_shuffle': None, 'resume': None, 'tuning': None, 'epoches': 72, 'last_epoch': -1, 'use_amp': True, 'use_ema': True, 'ema_decay': 0.9999, 'ema_warmups': 2000, 'sync_bn': True, 'clip_max_norm': 0.1, 'find_unused_parameters': False, 'seed': 0, 'print_freq': 100, 'checkpoint_freq': 1, 'output_dir': './output/rtdetrv2_r50vd_6x_coco', 'summary_dir': None, 'device': '', 'yaml_cfg': {'task': 'detection', 'evaluator': {'type': 'CocoEvaluator', 'iou_types': ['bbox']}, 'num_classes': 4, 'remap_mscoco_category': False, 'train_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': '/hscai/open/train', 'ann_file': '/hscai/open/train/_annotations.coco.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'Grayscale'}, {'type': 'RandomPhotometricDistort', 'p': 0.5}, {'type': 'RandomZoomOut', 'fill': 0}, {'type': 'RandomIoUCrop', 'p': 0.8}, {'type': 'SanitizeBoundingBoxes', 'min_size': 1}, {'type': 'RandomHorizontalFlip'}, {'type': 'Resize', 'size': [640, 640]}, {'type': 'SanitizeBoundingBoxes', 'min_size': 1}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}, {'type': 'ConvertBoxes', 'fmt': 'cxcywh', 'normalize': True}], 'policy': {'name': 'stop_epoch', 'epoch': 71, 'ops': ['RandomPhotometricDistort', 'RandomZoomOut', 'RandomIoUCrop']}}}, 'shuffle': True, 'num_workers': 16, 'drop_last': True, 'collate_fn': {'type': 'BatchImageCollateFuncion', 'scales': [480, 512, 544, 576, 608, 640, 640, 640, 672, 704, 736, 768, 800], 'stop_epoch': 71}, 'total_batch_size': 32}, 'val_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': '/hscai/open/valid', 'ann_file': '/hscai/open/valid/_annotations.coco.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'Grayscale'}, {'type': 'Resize', 'size': [640, 640]}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}]}}, 'shuffle': False, 'num_workers': 16, 'drop_last': False, 'collate_fn': {'type': 'BatchImageCollateFuncion'}, 'total_batch_size': 32}, 'print_freq': 100, 'output_dir': './output/rtdetrv2_r50vd_6x_coco', 'checkpoint_freq': 1, 'sync_bn': True, 'find_unused_parameters': False, 'use_amp': True, 'scaler': {'type': 'GradScaler', 'enabled': True}, 'use_ema': True, 'ema': {'type': 'ModelEMA', 'decay': 0.9999, 'warmups': 2000}, 'epoches': 72, 'clip_max_norm': 0.1, 'optimizer': {'type': 'AdamW', 'params': [{'params': '^(?=.*backbone)(?!.*norm).*$', 'lr': 1e-05}, {'params': '^(?=.*(?:encoder|decoder))(?=.*(?:norm|bn)).*$', 'weight_decay': 0.0}], 'lr': 0.0001, 'betas': [0.9, 0.999], 'weight_decay': 0.0001}, 'lr_scheduler': {'type': 'MultiStepLR', 'milestones': [1000], 'gamma': 0.1}, 'lr_warmup_scheduler': {'type': 'LinearWarmup', 'warmup_duration': 2000}, 'model': 'RTDETR', 'criterion': 'RTDETRCriterionv2', 'postprocessor': 'RTDETRPostProcessor', 'use_focal_loss': True, 'eval_spatial_size': [640, 640], 'RTDETR': {'backbone': 'PResNet', 'encoder': 'HybridEncoder', 'decoder': 'RTDETRTransformerv2'}, 'PResNet': {'depth': 50, 'variant': 'd', 'freeze_at': 0, 'return_idx': [1, 2, 3], 'num_stages': 4, 'freeze_norm': True, 'pretrained': False}, 'HybridEncoder': {'in_channels': [512, 1024, 2048], 'feat_strides': [8, 16, 32], 'hidden_dim': 256, 'use_encoder_idx': [2], 'num_encoder_layers': 1, 'nhead': 8, 'dim_feedforward': 1024, 'dropout': 0.0, 'enc_act': 'gelu', 'expansion': 1.0, 'depth_mult': 1, 'act': 'silu'}, 'RTDETRTransformerv2': {'feat_channels': [256, 256, 256], 'feat_strides': [8, 16, 32], 'hidden_dim': 256, 'num_levels': 3, 'num_layers': 6, 'num_queries': 300, 'num_denoising': 100, 'label_noise_ratio': 0.5, 'box_noise_scale': 1.0, 'eval_idx': -1, 'num_points': [4, 4, 4], 'cross_attn_method': 'default', 'query_select_method': 'default'}, 'RTDETRPostProcessor': {'num_top_queries': 300}, 'RTDETRCriterionv2': {'weight_dict': {'loss_vfl': 1, 'loss_bbox': 5, 'loss_giou': 2}, 'losses': ['vfl', 'boxes'], 'alpha': 0.75, 'gamma': 2.0, 'matcher': {'type': 'HungarianMatcher', 'weight_dict': {'cost_class': 2, 'cost_bbox': 5, 'cost_giou': 2}, 'alpha': 0.25, 'gamma': 2.0}}, '__include__': ['../dataset/open.yml', '../runtime.yml', './include/dataloader.yml', './include/optimizer.yml', './include/rtdetrv2_r50vd.yml'], 'config': 'configs/open/rtdetrv2_r50vd_6x_coco.yml', 'seed': 0, 'test_only': False, 'print_method': 'builtin', 'print_rank': 0}}
Start training
Initialized distributed mode...
Initial lr: [1e-05, 0.0001, 0.0001]
building train_dataloader with batch_size=16...
Loading annotations into memory...
Done (t=0.30s)
Creating index...
index created!
building val_dataloader with batch_size=16...
Loading annotations into memory...
Done (t=0.03s)
Creating index...
index created!
number of trainable parameters: 42706680
Epoch: [0]  [  0/276]  eta: 0:24:02  lr: 0.000000  loss: 33.8707 (33.8707)  loss_bbox: 0.5956 (0.5956)  loss_bbox_aux_0: 0.6045 (0.6045)  loss_bbox_aux_1: 0.5988 (0.5988)  loss_bbox_aux_2: 0.6033 (0.6033)  loss_bbox_aux_3: 0.6000 (0.6000)  loss_bbox_aux_4: 0.5969 (0.5969)  loss_bbox_dn_0: 0.3225 (0.3225)  loss_bbox_dn_1: 0.3225 (0.3225)  loss_bbox_dn_2: 0.3225 (0.3225)  loss_bbox_dn_3: 0.3225 (0.3225)  loss_bbox_dn_4: 0.3225 (0.3225)  loss_bbox_dn_5: 0.3225 (0.3225)  loss_bbox_enc_0: 0.6043 (0.6043)  loss_giou: 1.7140 (1.7140)  loss_giou_aux_0: 1.7447 (1.7447)  loss_giou_aux_1: 1.7298 (1.7298)  loss_giou_aux_2: 1.7347 (1.7347)  loss_giou_aux_3: 1.7178 (1.7178)  loss_giou_aux_4: 1.7259 (1.7259)  loss_giou_dn_0: 1.3655 (1.3655)  loss_giou_dn_1: 1.3655 (1.3655)  loss_giou_dn_2: 1.3655 (1.3655)  loss_giou_dn_3: 1.3655 (1.3655)  loss_giou_dn_4: 1.3655 (1.3655)  loss_giou_dn_5: 1.3655 (1.3655)  loss_giou_enc_0: 1.7402 (1.7402)  loss_vfl: 0.4358 (0.4358)  loss_vfl_aux_0: 0.3461 (0.3461)  loss_vfl_aux_1: 0.3654 (0.3654)  loss_vfl_aux_2: 0.3849 (0.3849)  loss_vfl_aux_3: 0.3459 (0.3459)  loss_vfl_aux_4: 0.3546 (0.3546)  loss_vfl_dn_0: 0.8323 (0.8323)  loss_vfl_dn_1: 0.8130 (0.8130)  loss_vfl_dn_2: 0.8123 (0.8123)  loss_vfl_dn_3: 0.7312 (0.7312)  loss_vfl_dn_4: 0.7576 (0.7576)  loss_vfl_dn_5: 0.9106 (0.9106)  loss_vfl_enc_0: 0.3427 (0.3427)  time: 5.2251  data: 2.3034  max mem: 10486
Epoch: [0]  [100/276]  eta: 0:02:33  lr: 0.000001  loss: 33.6939 (34.1764)  loss_bbox: 0.7197 (0.6652)  loss_bbox_aux_0: 0.7195 (0.6701)  loss_bbox_aux_1: 0.7283 (0.6748)  loss_bbox_aux_2: 0.7176 (0.6673)  loss_bbox_aux_3: 0.7197 (0.6668)  loss_bbox_aux_4: 0.7144 (0.6658)  loss_bbox_dn_0: 0.3249 (0.3030)  loss_bbox_dn_1: 0.3252 (0.3031)  loss_bbox_dn_2: 0.3254 (0.3032)  loss_bbox_dn_3: 0.3258 (0.3033)  loss_bbox_dn_4: 0.3261 (0.3034)  loss_bbox_dn_5: 0.3266 (0.3036)  loss_bbox_enc_0: 0.7376 (0.6899)  loss_giou: 2.0117 (1.9489)  loss_giou_aux_0: 2.0284 (1.9691)  loss_giou_aux_1: 2.0155 (1.9572)  loss_giou_aux_2: 2.0094 (1.9536)  loss_giou_aux_3: 2.0060 (1.9488)  loss_giou_aux_4: 2.0051 (1.9476)  loss_giou_dn_0: 1.3745 (1.3786)  loss_giou_dn_1: 1.3751 (1.3787)  loss_giou_dn_2: 1.3756 (1.3787)  loss_giou_dn_3: 1.3760 (1.3787)  loss_giou_dn_4: 1.3763 (1.3787)  loss_giou_dn_5: 1.3769 (1.3788)  loss_giou_enc_0: 2.0377 (1.9735)  loss_vfl: 0.1988 (0.2521)  loss_vfl_aux_0: 0.2323 (0.2398)  loss_vfl_aux_1: 0.2233 (0.2465)  loss_vfl_aux_2: 0.1841 (0.2294)  loss_vfl_aux_3: 0.1994 (0.2182)  loss_vfl_aux_4: 0.1971 (0.2198)  loss_vfl_dn_0: 0.6334 (0.7415)  loss_vfl_dn_1: 0.6104 (0.7329)  loss_vfl_dn_2: 0.4852 (0.6554)  loss_vfl_dn_3: 0.5065 (0.6232)  loss_vfl_dn_4: 0.4644 (0.5981)  loss_vfl_dn_5: 0.5167 (0.7075)  loss_vfl_enc_0: 0.1962 (0.2221)  time: 0.7983  data: 0.0371  max mem: 19678
Epoch: [0]  [200/276]  eta: 0:01:04  lr: 0.000001  loss: 29.0613 (32.1591)  loss_bbox: 0.5034 (0.6045)  loss_bbox_aux_0: 0.5107 (0.6122)  loss_bbox_aux_1: 0.5059 (0.6115)  loss_bbox_aux_2: 0.5042 (0.6069)  loss_bbox_aux_3: 0.5023 (0.6053)  loss_bbox_aux_4: 0.5055 (0.6048)  loss_bbox_dn_0: 0.2981 (0.3046)  loss_bbox_dn_1: 0.2976 (0.3048)  loss_bbox_dn_2: 0.2970 (0.3051)  loss_bbox_dn_3: 0.2966 (0.3055)  loss_bbox_dn_4: 0.2962 (0.3058)  loss_bbox_dn_5: 0.2958 (0.3063)  loss_bbox_enc_0: 0.5189 (0.6277)  loss_giou: 1.5055 (1.7760)  loss_giou_aux_0: 1.5158 (1.7959)  loss_giou_aux_1: 1.5122 (1.7859)  loss_giou_aux_2: 1.5107 (1.7819)  loss_giou_aux_3: 1.5066 (1.7780)  loss_giou_aux_4: 1.5073 (1.7764)  loss_giou_dn_0: 1.3741 (1.3786)  loss_giou_dn_1: 1.3720 (1.3786)  loss_giou_dn_2: 1.3694 (1.3786)  loss_giou_dn_3: 1.3694 (1.3788)  loss_giou_dn_4: 1.3692 (1.3791)  loss_giou_dn_5: 1.3702 (1.3798)  loss_giou_enc_0: 1.5252 (1.8043)  loss_vfl: 0.4020 (0.3131)  loss_vfl_aux_0: 0.3676 (0.2878)  loss_vfl_aux_1: 0.3887 (0.2974)  loss_vfl_aux_2: 0.4036 (0.2966)  loss_vfl_aux_3: 0.4056 (0.2948)  loss_vfl_aux_4: 0.4023 (0.2956)  loss_vfl_dn_0: 0.3545 (0.5786)  loss_vfl_dn_1: 0.3489 (0.5681)  loss_vfl_dn_2: 0.3558 (0.5219)  loss_vfl_dn_3: 0.3649 (0.5102)  loss_vfl_dn_4: 0.3663 (0.4941)  loss_vfl_dn_5: 0.3700 (0.5550)  loss_vfl_enc_0: 0.3505 (0.2690)  time: 0.8320  data: 0.0248  max mem: 19736
Epoch: [0]  [275/276]  eta: 0:00:00  lr: 0.000001  loss: 28.1665 (31.1913)  loss_bbox: 0.4570 (0.5744)  loss_bbox_aux_0: 0.4694 (0.5827)  loss_bbox_aux_1: 0.4621 (0.5804)  loss_bbox_aux_2: 0.4605 (0.5772)  loss_bbox_aux_3: 0.4579 (0.5752)  loss_bbox_aux_4: 0.4599 (0.5753)  loss_bbox_dn_0: 0.2932 (0.3028)  loss_bbox_dn_1: 0.2887 (0.3023)  loss_bbox_dn_2: 0.2856 (0.3021)  loss_bbox_dn_3: 0.2836 (0.3020)  loss_bbox_dn_4: 0.2821 (0.3020)  loss_bbox_dn_5: 0.2811 (0.3021)  loss_bbox_enc_0: 0.4840 (0.5970)  loss_giou: 1.4491 (1.6931)  loss_giou_aux_0: 1.4525 (1.7113)  loss_giou_aux_1: 1.4488 (1.7021)  loss_giou_aux_2: 1.4503 (1.6984)  loss_giou_aux_3: 1.4472 (1.6950)  loss_giou_aux_4: 1.4509 (1.6937)  loss_giou_dn_0: 1.3655 (1.3772)  loss_giou_dn_1: 1.3576 (1.3759)  loss_giou_dn_2: 1.3552 (1.3753)  loss_giou_dn_3: 1.3576 (1.3758)  loss_giou_dn_4: 1.3586 (1.3762)  loss_giou_dn_5: 1.3611 (1.3770)  loss_giou_enc_0: 1.4654 (1.7215)  loss_vfl: 0.3928 (0.3398)  loss_vfl_aux_0: 0.3789 (0.3114)  loss_vfl_aux_1: 0.3879 (0.3206)  loss_vfl_aux_2: 0.3876 (0.3209)  loss_vfl_aux_3: 0.3948 (0.3235)  loss_vfl_aux_4: 0.3937 (0.3251)  loss_vfl_dn_0: 0.3413 (0.5144)  loss_vfl_dn_1: 0.3356 (0.5047)  loss_vfl_dn_2: 0.3433 (0.4732)  loss_vfl_dn_3: 0.3457 (0.4655)  loss_vfl_dn_4: 0.3408 (0.4532)  loss_vfl_dn_5: 0.3459 (0.4991)  loss_vfl_enc_0: 0.3558 (0.2919)  time: 0.7739  data: 0.0229  max mem: 19736
Epoch: [0] Total time: 0:03:51 (0.8392 s / it)
Averaged stats: lr: 0.000001  loss: 28.1665 (31.1913)  loss_bbox: 0.4570 (0.5744)  loss_bbox_aux_0: 0.4694 (0.5827)  loss_bbox_aux_1: 0.4621 (0.5804)  loss_bbox_aux_2: 0.4605 (0.5772)  loss_bbox_aux_3: 0.4579 (0.5752)  loss_bbox_aux_4: 0.4599 (0.5753)  loss_bbox_dn_0: 0.2932 (0.3028)  loss_bbox_dn_1: 0.2887 (0.3023)  loss_bbox_dn_2: 0.2856 (0.3021)  loss_bbox_dn_3: 0.2836 (0.3020)  loss_bbox_dn_4: 0.2821 (0.3020)  loss_bbox_dn_5: 0.2811 (0.3021)  loss_bbox_enc_0: 0.4840 (0.5970)  loss_giou: 1.4491 (1.6931)  loss_giou_aux_0: 1.4525 (1.7113)  loss_giou_aux_1: 1.4488 (1.7021)  loss_giou_aux_2: 1.4503 (1.6984)  loss_giou_aux_3: 1.4472 (1.6950)  loss_giou_aux_4: 1.4509 (1.6937)  loss_giou_dn_0: 1.3655 (1.3772)  loss_giou_dn_1: 1.3576 (1.3759)  loss_giou_dn_2: 1.3552 (1.3753)  loss_giou_dn_3: 1.3576 (1.3758)  loss_giou_dn_4: 1.3586 (1.3762)  loss_giou_dn_5: 1.3611 (1.3770)  loss_giou_enc_0: 1.4654 (1.7215)  loss_vfl: 0.3928 (0.3398)  loss_vfl_aux_0: 0.3789 (0.3114)  loss_vfl_aux_1: 0.3879 (0.3206)  loss_vfl_aux_2: 0.3876 (0.3209)  loss_vfl_aux_3: 0.3948 (0.3235)  loss_vfl_aux_4: 0.3937 (0.3251)  loss_vfl_dn_0: 0.3413 (0.5144)  loss_vfl_dn_1: 0.3356 (0.5047)  loss_vfl_dn_2: 0.3433 (0.4732)  loss_vfl_dn_3: 0.3457 (0.4655)  loss_vfl_dn_4: 0.3408 (0.4532)  loss_vfl_dn_5: 0.3459 (0.4991)  loss_vfl_enc_0: 0.3558 (0.2919)
Test:  [ 0/43]  eta: 0:01:31    time: 2.1353  data: 1.5052  max mem: 19736
Test:  [10/43]  eta: 0:00:26    time: 0.8015  data: 0.1651  max mem: 19736
Test:  [20/43]  eta: 0:00:17    time: 0.6702  data: 0.0371  max mem: 19736
Test:  [30/43]  eta: 0:00:09    time: 0.6710  data: 0.0270  max mem: 19736
Test:  [40/43]  eta: 0:00:02    time: 0.6608  data: 0.0224  max mem: 19736
Test:  [42/43]  eta: 0:00:00    time: 0.6318  data: 0.0224  max mem: 19736
Test: Total time: 0:00:29 (0.6947 s / it)
Averaged stats: 
Accumulating evaluation results...
DONE (t=3.33s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.00155
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.00929
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.00032
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00206
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.00289
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.01459
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.04389
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06797
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
best_stat: {'epoch': 0, 'coco_eval_bbox': 0.0015542334985911568}
Epoch: [1]  [  0/276]  eta: 0:15:21  lr: 0.000001  loss: 28.3279 (28.3279)  loss_bbox: 0.4769 (0.4769)  loss_bbox_aux_0: 0.4833 (0.4833)  loss_bbox_aux_1: 0.4756 (0.4756)  loss_bbox_aux_2: 0.4782 (0.4782)  loss_bbox_aux_3: 0.4778 (0.4778)  loss_bbox_aux_4: 0.4801 (0.4801)  loss_bbox_dn_0: 0.3110 (0.3110)  loss_bbox_dn_1: 0.3068 (0.3068)  loss_bbox_dn_2: 0.3039 (0.3039)  loss_bbox_dn_3: 0.3018 (0.3018)  loss_bbox_dn_4: 0.3004 (0.3004)  loss_bbox_dn_5: 0.2990 (0.2990)  loss_bbox_enc_0: 0.4966 (0.4966)  loss_giou: 1.4007 (1.4007)  loss_giou_aux_0: 1.4105 (1.4105)  loss_giou_aux_1: 1.4056 (1.4056)  loss_giou_aux_2: 1.4013 (1.4013)  loss_giou_aux_3: 1.3969 (1.3969)  loss_giou_aux_4: 1.3976 (1.3976)  loss_giou_dn_0: 1.3703 (1.3703)  loss_giou_dn_1: 1.3606 (1.3606)  loss_giou_dn_2: 1.3559 (1.3559)  loss_giou_dn_3: 1.3541 (1.3541)  loss_giou_dn_4: 1.3526 (1.3526)  loss_giou_dn_5: 1.3522 (1.3522)  loss_giou_enc_0: 1.4494 (1.4494)  loss_vfl: 0.4604 (0.4604)  loss_vfl_aux_0: 0.4365 (0.4365)  loss_vfl_aux_1: 0.4304 (0.4304)  loss_vfl_aux_2: 0.4266 (0.4266)  loss_vfl_aux_3: 0.4283 (0.4283)  loss_vfl_aux_4: 0.4382 (0.4382)  loss_vfl_dn_0: 0.3473 (0.3473)  loss_vfl_dn_1: 0.3434 (0.3434)  loss_vfl_dn_2: 0.3488 (0.3488)  loss_vfl_dn_3: 0.3547 (0.3547)  loss_vfl_dn_4: 0.3527 (0.3527)  loss_vfl_dn_5: 0.3551 (0.3551)  loss_vfl_enc_0: 0.4061 (0.4061)  time: 3.3392  data: 2.5913  max mem: 19736
Epoch: [1]  [100/276]  eta: 0:02:28  lr: 0.000002  loss: 27.8689 (28.3575)  loss_bbox: 0.4534 (0.4928)  loss_bbox_aux_0: 0.4780 (0.5046)  loss_bbox_aux_1: 0.4699 (0.4994)  loss_bbox_aux_2: 0.4677 (0.4992)  loss_bbox_aux_3: 0.4622 (0.4956)  loss_bbox_aux_4: 0.4550 (0.4959)  loss_bbox_dn_0: 0.2818 (0.3015)  loss_bbox_dn_1: 0.2788 (0.2980)  loss_bbox_dn_2: 0.2776 (0.2961)  loss_bbox_dn_3: 0.2772 (0.2952)  loss_bbox_dn_4: 0.2773 (0.2947)  loss_bbox_dn_5: 0.2777 (0.2948)  loss_bbox_enc_0: 0.4968 (0.5168)  loss_giou: 1.3716 (1.4269)  loss_giou_aux_0: 1.4060 (1.4497)  loss_giou_aux_1: 1.3983 (1.4435)  loss_giou_aux_2: 1.3925 (1.4400)  loss_giou_aux_3: 1.3846 (1.4346)  loss_giou_aux_4: 1.3797 (1.4317)  loss_giou_dn_0: 1.3485 (1.3592)  loss_giou_dn_1: 1.3438 (1.3541)  loss_giou_dn_2: 1.3455 (1.3531)  loss_giou_dn_3: 1.3440 (1.3542)  loss_giou_dn_4: 1.3442 (1.3541)  loss_giou_dn_5: 1.3407 (1.3548)  loss_giou_enc_0: 1.4249 (1.4627)  loss_vfl: 0.4296 (0.4190)  loss_vfl_aux_0: 0.4141 (0.3972)  loss_vfl_aux_1: 0.4139 (0.3960)  loss_vfl_aux_2: 0.4238 (0.4002)  loss_vfl_aux_3: 0.4272 (0.4072)  loss_vfl_aux_4: 0.4269 (0.4107)  loss_vfl_dn_0: 0.3392 (0.3409)  loss_vfl_dn_1: 0.3372 (0.3373)  loss_vfl_dn_2: 0.3394 (0.3423)  loss_vfl_dn_3: 0.3400 (0.3417)  loss_vfl_dn_4: 0.3414 (0.3422)  loss_vfl_dn_5: 0.3439 (0.3445)  loss_vfl_enc_0: 0.3773 (0.3749)  time: 0.8383  data: 0.0410  max mem: 19736
Epoch: [1]  [200/276]  eta: 0:01:03  lr: 0.000002  loss: 26.3845 (27.8989)  loss_bbox: 0.3031 (0.4450)  loss_bbox_aux_0: 0.4139 (0.4863)  loss_bbox_aux_1: 0.3747 (0.4743)  loss_bbox_aux_2: 0.3392 (0.4658)  loss_bbox_aux_3: 0.3195 (0.4566)  loss_bbox_aux_4: 0.3066 (0.4514)  loss_bbox_dn_0: 0.2655 (0.2967)  loss_bbox_dn_1: 0.2566 (0.2923)  loss_bbox_dn_2: 0.2542 (0.2898)  loss_bbox_dn_3: 0.2584 (0.2898)  loss_bbox_dn_4: 0.2599 (0.2903)  loss_bbox_dn_5: 0.2636 (0.2913)  loss_bbox_enc_0: 0.4487 (0.5025)  loss_giou: 1.1834 (1.3471)  loss_giou_aux_0: 1.3618 (1.4173)  loss_giou_aux_1: 1.2976 (1.3963)  loss_giou_aux_2: 1.2384 (1.3795)  loss_giou_aux_3: 1.2063 (1.3651)  loss_giou_aux_4: 1.1867 (1.3560)  loss_giou_dn_0: 1.3438 (1.3527)  loss_giou_dn_1: 1.3181 (1.3436)  loss_giou_dn_2: 1.2990 (1.3372)  loss_giou_dn_3: 1.2951 (1.3363)  loss_giou_dn_4: 1.2934 (1.3347)  loss_giou_dn_5: 1.2944 (1.3351)  loss_giou_enc_0: 1.4193 (1.4394)  loss_vfl: 0.5847 (0.4769)  loss_vfl_aux_0: 0.4333 (0.4137)  loss_vfl_aux_1: 0.4828 (0.4247)  loss_vfl_aux_2: 0.5380 (0.4414)  loss_vfl_aux_3: 0.5657 (0.4562)  loss_vfl_aux_4: 0.5750 (0.4656)  loss_vfl_dn_0: 0.3341 (0.3390)  loss_vfl_dn_1: 0.3418 (0.3381)  loss_vfl_dn_2: 0.3516 (0.3446)  loss_vfl_dn_3: 0.3521 (0.3450)  loss_vfl_dn_4: 0.3549 (0.3472)  loss_vfl_dn_5: 0.3540 (0.3491)  loss_vfl_enc_0: 0.3937 (0.3851)  time: 0.8320  data: 0.0228  max mem: 19736
Epoch: [1]  [275/276]  eta: 0:00:00  lr: 0.000003  loss: 25.9678 (27.5387)  loss_bbox: 0.2799 (0.4072)  loss_bbox_aux_0: 0.3712 (0.4659)  loss_bbox_aux_1: 0.3269 (0.4438)  loss_bbox_aux_2: 0.3046 (0.4309)  loss_bbox_aux_3: 0.2914 (0.4197)  loss_bbox_aux_4: 0.2849 (0.4133)  loss_bbox_dn_0: 0.2663 (0.2921)  loss_bbox_dn_1: 0.2611 (0.2871)  loss_bbox_dn_2: 0.2662 (0.2862)  loss_bbox_dn_3: 0.2693 (0.2871)  loss_bbox_dn_4: 0.2721 (0.2882)  loss_bbox_dn_5: 0.2755 (0.2895)  loss_bbox_enc_0: 0.4133 (0.4893)  loss_giou: 1.0972 (1.2935)  loss_giou_aux_0: 1.1980 (1.3808)  loss_giou_aux_1: 1.1284 (1.3430)  loss_giou_aux_2: 1.1042 (1.3234)  loss_giou_aux_3: 1.0980 (1.3098)  loss_giou_aux_4: 1.1033 (1.3015)  loss_giou_dn_0: 1.3042 (1.3445)  loss_giou_dn_1: 1.2641 (1.3281)  loss_giou_dn_2: 1.2587 (1.3208)  loss_giou_dn_3: 1.2642 (1.3208)  loss_giou_dn_4: 1.2610 (1.3202)  loss_giou_dn_5: 1.2646 (1.3214)  loss_giou_enc_0: 1.3075 (1.4189)  loss_vfl: 0.6644 (0.5220)  loss_vfl_aux_0: 0.5635 (0.4387)  loss_vfl_aux_1: 0.6394 (0.4671)  loss_vfl_aux_2: 0.6553 (0.4884)  loss_vfl_aux_3: 0.6621 (0.5026)  loss_vfl_aux_4: 0.6689 (0.5122)  loss_vfl_dn_0: 0.3495 (0.3400)  loss_vfl_dn_1: 0.3625 (0.3427)  loss_vfl_dn_2: 0.3662 (0.3491)  loss_vfl_dn_3: 0.3621 (0.3486)  loss_vfl_dn_4: 0.3636 (0.3510)  loss_vfl_dn_5: 0.3622 (0.3520)  loss_vfl_enc_0: 0.4506 (0.3973)  time: 0.8840  data: 0.0256  max mem: 19736
Epoch: [1] Total time: 0:03:54 (0.8511 s / it)
Averaged stats: lr: 0.000003  loss: 25.9678 (27.5387)  loss_bbox: 0.2799 (0.4072)  loss_bbox_aux_0: 0.3712 (0.4659)  loss_bbox_aux_1: 0.3269 (0.4438)  loss_bbox_aux_2: 0.3046 (0.4309)  loss_bbox_aux_3: 0.2914 (0.4197)  loss_bbox_aux_4: 0.2849 (0.4133)  loss_bbox_dn_0: 0.2663 (0.2921)  loss_bbox_dn_1: 0.2611 (0.2871)  loss_bbox_dn_2: 0.2662 (0.2862)  loss_bbox_dn_3: 0.2693 (0.2871)  loss_bbox_dn_4: 0.2721 (0.2882)  loss_bbox_dn_5: 0.2755 (0.2895)  loss_bbox_enc_0: 0.4133 (0.4893)  loss_giou: 1.0972 (1.2935)  loss_giou_aux_0: 1.1980 (1.3808)  loss_giou_aux_1: 1.1284 (1.3430)  loss_giou_aux_2: 1.1042 (1.3234)  loss_giou_aux_3: 1.0980 (1.3098)  loss_giou_aux_4: 1.1033 (1.3015)  loss_giou_dn_0: 1.3042 (1.3445)  loss_giou_dn_1: 1.2641 (1.3281)  loss_giou_dn_2: 1.2587 (1.3208)  loss_giou_dn_3: 1.2642 (1.3208)  loss_giou_dn_4: 1.2610 (1.3202)  loss_giou_dn_5: 1.2646 (1.3214)  loss_giou_enc_0: 1.3075 (1.4189)  loss_vfl: 0.6644 (0.5220)  loss_vfl_aux_0: 0.5635 (0.4387)  loss_vfl_aux_1: 0.6394 (0.4671)  loss_vfl_aux_2: 0.6553 (0.4884)  loss_vfl_aux_3: 0.6621 (0.5026)  loss_vfl_aux_4: 0.6689 (0.5122)  loss_vfl_dn_0: 0.3495 (0.3400)  loss_vfl_dn_1: 0.3625 (0.3427)  loss_vfl_dn_2: 0.3662 (0.3491)  loss_vfl_dn_3: 0.3621 (0.3486)  loss_vfl_dn_4: 0.3636 (0.3510)  loss_vfl_dn_5: 0.3622 (0.3520)  loss_vfl_enc_0: 0.4506 (0.3973)
Test:  [ 0/43]  eta: 0:01:50    time: 2.5802  data: 1.9472  max mem: 19736
Test:  [10/43]  eta: 0:00:28    time: 0.8492  data: 0.1873  max mem: 19736
Test:  [20/43]  eta: 0:00:17    time: 0.6901  data: 0.0290  max mem: 19736
Test:  [30/43]  eta: 0:00:09    time: 0.7002  data: 0.0272  max mem: 19736
Test:  [40/43]  eta: 0:00:02    time: 0.6942  data: 0.0208  max mem: 19736
Test:  [42/43]  eta: 0:00:00    time: 0.6634  data: 0.0195  max mem: 19736
Test: Total time: 0:00:31 (0.7322 s / it)
Averaged stats: 
Accumulating evaluation results...
DONE (t=3.62s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.01315
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.04120
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.00575
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.01636
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00752
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00198
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.01505
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.05674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.14055
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.15864
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.12205
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00126
best_stat: {'epoch': 1, 'coco_eval_bbox': 0.013149090385736199}
Epoch: [2]  [  0/276]  eta: 0:16:14  lr: 0.000003  loss: 25.2273 (25.2273)  loss_bbox: 0.2462 (0.2462)  loss_bbox_aux_0: 0.3030 (0.3030)  loss_bbox_aux_1: 0.2733 (0.2733)  loss_bbox_aux_2: 0.2609 (0.2609)  loss_bbox_aux_3: 0.2551 (0.2551)  loss_bbox_aux_4: 0.2464 (0.2464)  loss_bbox_dn_0: 0.2470 (0.2470)  loss_bbox_dn_1: 0.2453 (0.2453)  loss_bbox_dn_2: 0.2501 (0.2501)  loss_bbox_dn_3: 0.2511 (0.2511)  loss_bbox_dn_4: 0.2517 (0.2517)  loss_bbox_dn_5: 0.2532 (0.2532)  loss_bbox_enc_0: 0.3604 (0.3604)  loss_giou: 1.1143 (1.1143)  loss_giou_aux_0: 1.1865 (1.1865)  loss_giou_aux_1: 1.1483 (1.1483)  loss_giou_aux_2: 1.1313 (1.1313)  loss_giou_aux_3: 1.1317 (1.1317)  loss_giou_aux_4: 1.1249 (1.1249)  loss_giou_dn_0: 1.2935 (1.2935)  loss_giou_dn_1: 1.2596 (1.2596)  loss_giou_dn_2: 1.2611 (1.2611)  loss_giou_dn_3: 1.2574 (1.2574)  loss_giou_dn_4: 1.2570 (1.2570)  loss_giou_dn_5: 1.2545 (1.2545)  loss_giou_enc_0: 1.3012 (1.3012)  loss_vfl: 0.5928 (0.5928)  loss_vfl_aux_0: 0.5314 (0.5314)  loss_vfl_aux_1: 0.5603 (0.5603)  loss_vfl_aux_2: 0.5802 (0.5802)  loss_vfl_aux_3: 0.5891 (0.5891)  loss_vfl_aux_4: 0.5908 (0.5908)  loss_vfl_dn_0: 0.3518 (0.3518)  loss_vfl_dn_1: 0.3605 (0.3605)  loss_vfl_dn_2: 0.3625 (0.3625)  loss_vfl_dn_3: 0.3639 (0.3639)  loss_vfl_dn_4: 0.3661 (0.3661)  loss_vfl_dn_5: 0.3685 (0.3685)  loss_vfl_enc_0: 0.4443 (0.4443)  time: 3.5320  data: 2.8120  max mem: 19736
Epoch: [2]  [100/276]  eta: 0:02:32  lr: 0.000003  loss: 25.8994 (25.9411)  loss_bbox: 0.2526 (0.2631)  loss_bbox_aux_0: 0.3229 (0.3365)  loss_bbox_aux_1: 0.2819 (0.2968)  loss_bbox_aux_2: 0.2682 (0.2824)  loss_bbox_aux_3: 0.2626 (0.2715)  loss_bbox_aux_4: 0.2570 (0.2662)  loss_bbox_dn_0: 0.2761 (0.2742)  loss_bbox_dn_1: 0.2764 (0.2719)  loss_bbox_dn_2: 0.2756 (0.2743)  loss_bbox_dn_3: 0.2753 (0.2752)  loss_bbox_dn_4: 0.2772 (0.2758)  loss_bbox_dn_5: 0.2795 (0.2767)  loss_bbox_enc_0: 0.3653 (0.3944)  loss_giou: 1.0347 (1.0867)  loss_giou_aux_0: 1.0843 (1.1557)  loss_giou_aux_1: 1.0661 (1.1141)  loss_giou_aux_2: 1.0541 (1.1009)  loss_giou_aux_3: 1.0387 (1.0948)  loss_giou_aux_4: 1.0376 (1.0899)  loss_giou_dn_0: 1.2634 (1.2795)  loss_giou_dn_1: 1.2406 (1.2541)  loss_giou_dn_2: 1.2347 (1.2490)  loss_giou_dn_3: 1.2339 (1.2498)  loss_giou_dn_4: 1.2322 (1.2504)  loss_giou_dn_5: 1.2326 (1.2519)  loss_giou_enc_0: 1.1791 (1.2566)  loss_vfl: 0.7310 (0.6954)  loss_vfl_aux_0: 0.6914 (0.6190)  loss_vfl_aux_1: 0.7065 (0.6582)  loss_vfl_aux_2: 0.7107 (0.6744)  loss_vfl_aux_3: 0.7180 (0.6818)  loss_vfl_aux_4: 0.7307 (0.6887)  loss_vfl_dn_0: 0.3633 (0.3587)  loss_vfl_dn_1: 0.3669 (0.3660)  loss_vfl_dn_2: 0.3723 (0.3697)  loss_vfl_dn_3: 0.3744 (0.3688)  loss_vfl_dn_4: 0.3750 (0.3704)  loss_vfl_dn_5: 0.3790 (0.3715)  loss_vfl_enc_0: 0.5952 (0.5260)  time: 0.8207  data: 0.0226  max mem: 19736
Epoch: [2]  [200/276]  eta: 0:01:04  lr: 0.000004  loss: 24.8615 (25.6280)  loss_bbox: 0.2235 (0.2497)  loss_bbox_aux_0: 0.2371 (0.3002)  loss_bbox_aux_1: 0.2295 (0.2717)  loss_bbox_aux_2: 0.2257 (0.2626)  loss_bbox_aux_3: 0.2271 (0.2553)  loss_bbox_aux_4: 0.2193 (0.2521)  loss_bbox_dn_0: 0.2525 (0.2712)  loss_bbox_dn_1: 0.2504 (0.2686)  loss_bbox_dn_2: 0.2510 (0.2697)  loss_bbox_dn_3: 0.2509 (0.2699)  loss_bbox_dn_4: 0.2505 (0.2699)  loss_bbox_dn_5: 0.2506 (0.2704)  loss_bbox_enc_0: 0.2845 (0.3507)  loss_giou: 1.0110 (1.0544)  loss_giou_aux_0: 1.0339 (1.1082)  loss_giou_aux_1: 1.0273 (1.0760)  loss_giou_aux_2: 1.0166 (1.0656)  loss_giou_aux_3: 1.0123 (1.0610)  loss_giou_aux_4: 1.0129 (1.0572)  loss_giou_dn_0: 1.2320 (1.2615)  loss_giou_dn_1: 1.2094 (1.2385)  loss_giou_dn_2: 1.2023 (1.2323)  loss_giou_dn_3: 1.2026 (1.2321)  loss_giou_dn_4: 1.2020 (1.2315)  loss_giou_dn_5: 1.2029 (1.2325)  loss_giou_enc_0: 1.1221 (1.2002)  loss_vfl: 0.7351 (0.7219)  loss_vfl_aux_0: 0.7266 (0.6624)  loss_vfl_aux_1: 0.7139 (0.6891)  loss_vfl_aux_2: 0.7131 (0.7012)  loss_vfl_aux_3: 0.7236 (0.7081)  loss_vfl_aux_4: 0.7207 (0.7154)  loss_vfl_dn_0: 0.3734 (0.3647)  loss_vfl_dn_1: 0.3779 (0.3700)  loss_vfl_dn_2: 0.3824 (0.3743)  loss_vfl_dn_3: 0.3809 (0.3739)  loss_vfl_dn_4: 0.3833 (0.3758)  loss_vfl_dn_5: 0.3846 (0.3776)  loss_vfl_enc_0: 0.6492 (0.5808)  time: 0.8306  data: 0.0209  max mem: 19736
Epoch: [2]  [275/276]  eta: 0:00:00  lr: 0.000004  loss: 24.4218 (25.3722)  loss_bbox: 0.1965 (0.2394)  loss_bbox_aux_0: 0.2076 (0.2801)  loss_bbox_aux_1: 0.2008 (0.2570)  loss_bbox_aux_2: 0.2000 (0.2498)  loss_bbox_aux_3: 0.1991 (0.2440)  loss_bbox_aux_4: 0.2000 (0.2413)  loss_bbox_dn_0: 0.2348 (0.2655)  loss_bbox_dn_1: 0.2286 (0.2623)  loss_bbox_dn_2: 0.2286 (0.2628)  loss_bbox_dn_3: 0.2283 (0.2627)  loss_bbox_dn_4: 0.2280 (0.2626)  loss_bbox_dn_5: 0.2281 (0.2630)  loss_bbox_enc_0: 0.2348 (0.3255)  loss_giou: 0.9627 (1.0373)  loss_giou_aux_0: 1.0177 (1.0870)  loss_giou_aux_1: 0.9923 (1.0579)  loss_giou_aux_2: 0.9767 (1.0476)  loss_giou_aux_3: 0.9730 (1.0435)  loss_giou_aux_4: 0.9669 (1.0399)  loss_giou_dn_0: 1.2201 (1.2509)  loss_giou_dn_1: 1.1889 (1.2272)  loss_giou_dn_2: 1.1755 (1.2200)  loss_giou_dn_3: 1.1700 (1.2194)  loss_giou_dn_4: 1.1694 (1.2185)  loss_giou_dn_5: 1.1712 (1.2192)  loss_giou_enc_0: 1.1025 (1.1764)  loss_vfl: 0.7603 (0.7309)  loss_vfl_aux_0: 0.7231 (0.6755)  loss_vfl_aux_1: 0.7261 (0.6977)  loss_vfl_aux_2: 0.7407 (0.7105)  loss_vfl_aux_3: 0.7500 (0.7168)  loss_vfl_aux_4: 0.7581 (0.7243)  loss_vfl_dn_0: 0.3766 (0.3675)  loss_vfl_dn_1: 0.3824 (0.3725)  loss_vfl_dn_2: 0.3904 (0.3772)  loss_vfl_dn_3: 0.3905 (0.3770)  loss_vfl_dn_4: 0.3936 (0.3792)  loss_vfl_dn_5: 0.3942 (0.3811)  loss_vfl_enc_0: 0.6321 (0.6013)  time: 0.8587  data: 0.0256  max mem: 19736
Epoch: [2] Total time: 0:03:55 (0.8523 s / it)
Averaged stats: lr: 0.000004  loss: 24.4218 (25.3722)  loss_bbox: 0.1965 (0.2394)  loss_bbox_aux_0: 0.2076 (0.2801)  loss_bbox_aux_1: 0.2008 (0.2570)  loss_bbox_aux_2: 0.2000 (0.2498)  loss_bbox_aux_3: 0.1991 (0.2440)  loss_bbox_aux_4: 0.2000 (0.2413)  loss_bbox_dn_0: 0.2348 (0.2655)  loss_bbox_dn_1: 0.2286 (0.2623)  loss_bbox_dn_2: 0.2286 (0.2628)  loss_bbox_dn_3: 0.2283 (0.2627)  loss_bbox_dn_4: 0.2280 (0.2626)  loss_bbox_dn_5: 0.2281 (0.2630)  loss_bbox_enc_0: 0.2348 (0.3255)  loss_giou: 0.9627 (1.0373)  loss_giou_aux_0: 1.0177 (1.0870)  loss_giou_aux_1: 0.9923 (1.0579)  loss_giou_aux_2: 0.9767 (1.0476)  loss_giou_aux_3: 0.9730 (1.0435)  loss_giou_aux_4: 0.9669 (1.0399)  loss_giou_dn_0: 1.2201 (1.2509)  loss_giou_dn_1: 1.1889 (1.2272)  loss_giou_dn_2: 1.1755 (1.2200)  loss_giou_dn_3: 1.1700 (1.2194)  loss_giou_dn_4: 1.1694 (1.2185)  loss_giou_dn_5: 1.1712 (1.2192)  loss_giou_enc_0: 1.1025 (1.1764)  loss_vfl: 0.7603 (0.7309)  loss_vfl_aux_0: 0.7231 (0.6755)  loss_vfl_aux_1: 0.7261 (0.6977)  loss_vfl_aux_2: 0.7407 (0.7105)  loss_vfl_aux_3: 0.7500 (0.7168)  loss_vfl_aux_4: 0.7581 (0.7243)  loss_vfl_dn_0: 0.3766 (0.3675)  loss_vfl_dn_1: 0.3824 (0.3725)  loss_vfl_dn_2: 0.3904 (0.3772)  loss_vfl_dn_3: 0.3905 (0.3770)  loss_vfl_dn_4: 0.3936 (0.3792)  loss_vfl_dn_5: 0.3942 (0.3811)  loss_vfl_enc_0: 0.6321 (0.6013)
Test:  [ 0/43]  eta: 0:01:39    time: 2.3127  data: 1.6970  max mem: 19736
Test:  [10/43]  eta: 0:00:28    time: 0.8632  data: 0.2201  max mem: 19736
Test:  [20/43]  eta: 0:00:17    time: 0.6816  data: 0.0402  max mem: 19736
Test:  [30/43]  eta: 0:00:09    time: 0.6736  data: 0.0371  max mem: 19736
Test:  [40/43]  eta: 0:00:02    time: 0.6797  data: 0.0438  max mem: 19736
Test:  [42/43]  eta: 0:00:00    time: 0.6376  data: 0.0133  max mem: 19736
Test: Total time: 0:00:30 (0.7140 s / it)
Averaged stats: 
Accumulating evaluation results...
DONE (t=3.50s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.02780
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.07407
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.01337
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.02952
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.02920
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.01254
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.03304
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.10895
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22323
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.23387
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.21479
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.05469
best_stat: {'epoch': 2, 'coco_eval_bbox': 0.027802006135425744}
Epoch: [3]  [  0/276]  eta: 0:17:11  lr: 0.000004  loss: 24.6811 (24.6811)  loss_bbox: 0.1834 (0.1834)  loss_bbox_aux_0: 0.2056 (0.2056)  loss_bbox_aux_1: 0.1950 (0.1950)  loss_bbox_aux_2: 0.1876 (0.1876)  loss_bbox_aux_3: 0.1839 (0.1839)  loss_bbox_aux_4: 0.1849 (0.1849)  loss_bbox_dn_0: 0.2304 (0.2304)  loss_bbox_dn_1: 0.2239 (0.2239)  loss_bbox_dn_2: 0.2211 (0.2211)  loss_bbox_dn_3: 0.2193 (0.2193)  loss_bbox_dn_4: 0.2171 (0.2171)  loss_bbox_dn_5: 0.2162 (0.2162)  loss_bbox_enc_0: 0.2435 (0.2435)  loss_giou: 0.9673 (0.9673)  loss_giou_aux_0: 1.0140 (1.0140)  loss_giou_aux_1: 0.9913 (0.9913)  loss_giou_aux_2: 0.9875 (0.9875)  loss_giou_aux_3: 0.9845 (0.9845)  loss_giou_aux_4: 0.9713 (0.9713)  loss_giou_dn_0: 1.2175 (1.2175)  loss_giou_dn_1: 1.1841 (1.1841)  loss_giou_dn_2: 1.1693 (1.1693)  loss_giou_dn_3: 1.1677 (1.1677)  loss_giou_dn_4: 1.1625 (1.1625)  loss_giou_dn_5: 1.1614 (1.1614)  loss_giou_enc_0: 1.0998 (1.0998)  loss_vfl: 0.8328 (0.8328)  loss_vfl_aux_0: 0.7693 (0.7693)  loss_vfl_aux_1: 0.7686 (0.7686)  loss_vfl_aux_2: 0.7910 (0.7910)  loss_vfl_aux_3: 0.8022 (0.8022)  loss_vfl_aux_4: 0.8093 (0.8093)  loss_vfl_dn_0: 0.3875 (0.3875)  loss_vfl_dn_1: 0.3954 (0.3954)  loss_vfl_dn_2: 0.4030 (0.4030)  loss_vfl_dn_3: 0.4043 (0.4043)  loss_vfl_dn_4: 0.4066 (0.4066)  loss_vfl_dn_5: 0.4127 (0.4127)  loss_vfl_enc_0: 0.7085 (0.7085)  time: 3.7359  data: 2.8761  max mem: 19736
Epoch: [3]  [100/276]  eta: 0:02:32  lr: 0.000005  loss: 24.1917 (24.5466)  loss_bbox: 0.1942 (0.2060)  loss_bbox_aux_0: 0.2031 (0.2215)  loss_bbox_aux_1: 0.1982 (0.2135)  loss_bbox_aux_2: 0.1953 (0.2103)  loss_bbox_aux_3: 0.1949 (0.2083)  loss_bbox_aux_4: 0.1942 (0.2069)  loss_bbox_dn_0: 0.2491 (0.2566)  loss_bbox_dn_1: 0.2392 (0.2507)  loss_bbox_dn_2: 0.2352 (0.2489)  loss_bbox_dn_3: 0.2327 (0.2477)  loss_bbox_dn_4: 0.2312 (0.2471)  loss_bbox_dn_5: 0.2308 (0.2471)  loss_bbox_enc_0: 0.2353 (0.2508)  loss_giou: 0.9607 (0.9605)  loss_giou_aux_0: 0.9943 (1.0072)  loss_giou_aux_1: 0.9757 (0.9818)  loss_giou_aux_2: 0.9652 (0.9715)  loss_giou_aux_3: 0.9629 (0.9668)  loss_giou_aux_4: 0.9631 (0.9633)  loss_giou_dn_0: 1.2061 (1.2122)  loss_giou_dn_1: 1.1772 (1.1811)  loss_giou_dn_2: 1.1665 (1.1711)  loss_giou_dn_3: 1.1615 (1.1686)  loss_giou_dn_4: 1.1577 (1.1671)  loss_giou_dn_5: 1.1577 (1.1677)  loss_giou_enc_0: 1.0705 (1.0929)  loss_vfl: 0.7729 (0.7768)  loss_vfl_aux_0: 0.7136 (0.7231)  loss_vfl_aux_1: 0.7502 (0.7392)  loss_vfl_aux_2: 0.7612 (0.7526)  loss_vfl_aux_3: 0.7642 (0.7604)  loss_vfl_aux_4: 0.7539 (0.7697)  loss_vfl_dn_0: 0.3802 (0.3763)  loss_vfl_dn_1: 0.3871 (0.3824)  loss_vfl_dn_2: 0.3909 (0.3878)  loss_vfl_dn_3: 0.3903 (0.3889)  loss_vfl_dn_4: 0.3933 (0.3915)  loss_vfl_dn_5: 0.3945 (0.3939)  loss_vfl_enc_0: 0.6770 (0.6767)  time: 0.8163  data: 0.0212  max mem: 19736
